{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6fabe7e3-ee54-4dad-abab-7ebb1f6b5fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1979],\n",
       "        [0.2000]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  \n",
    "from torch import nn  \n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))  \n",
    "X = torch.rand(size=(2, 4))  \n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e0f84-d46e-47bc-9259-abfc54621024",
   "metadata": {},
   "source": [
    "## 一.参数访问"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16be0fa-9da3-4e6c-a2fa-1bb1f9805d6f",
   "metadata": {},
   "source": [
    "### 1.访问一个层的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "992591e8-e3c6-4b81-b782-391cf67bd070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.2449,  0.1801,  0.0567,  0.1355, -0.3012, -0.1621,  0.2232, -0.3003]])), ('bias', tensor([0.0938]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae80f97-2bc4-42be-a4f0-917dce5b078d",
   "metadata": {},
   "source": [
    "说明：访问的是模型的第3层(Liner(8，1))，这个全连接层包含两个参数,分别是该层的权重(o,h)和偏置(1,o)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d115d8-ce53-46f6-88a4-fe026cc4152a",
   "metadata": {},
   "source": [
    "### 2.访问单独的参数\n",
    "下面的代码从第二个全连接层(即第三个神  经网络层)提取偏置,提取后返回的是一个参数类实例,并进一步访问该参数的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf718bf-6c60-4a9a-94db-4d9bd8e8077f",
   "metadata": {},
   "source": [
    "(1)参数类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3e57a97a-48d9-458e-9849-3e6d08d29b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b4c43-0070-4cca-86d6-9334638e39b8",
   "metadata": {},
   "source": [
    "(2)参数的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b626ae16-b0a3-4ae7-9e15-167d78ae413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0938], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net[2].bias)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06956761-a034-4f19-aeb3-afd0a12acd73",
   "metadata": {},
   "source": [
    "(3)参数的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd86b118-a1d7-436c-a4b3-a843f6220ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0938])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75b035-f269-4f37-ba9a-f0bf80b2fb4a",
   "metadata": {},
   "source": [
    "另一种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a038746-ce96-466a-9ae1-cc95b669bf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0938])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9a9ff-6371-4613-a98e-755cc07c5fe8",
   "metadata": {},
   "source": [
    "（4）访问参数的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b8d4dfbd-588d-481c-b35f-0ef32abac429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(net[2].bias.grad) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b7556-5daf-42df-bd5d-891bdede493d",
   "metadata": {},
   "source": [
    "(5)一次性访问一个全连接层的所有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84d70e17-ec97-4866-a970-da2dbe843704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([1, 8])) ('bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[2].named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb669f-e209-4abb-81f9-19b3e4ccb532",
   "metadata": {},
   "source": [
    "（6）一次性访问所有全连接层的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7c454fa-ddab-49bb-acfe-b96914ed9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6e4a8-0792-4d1e-9eb5-217291bec425",
   "metadata": {},
   "source": [
    "### 3.在嵌套的block中访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c8a2c06c-6cf0-4b2b-bfba-ddb08185a483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (block 0): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 1): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 3): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():  \n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),  nn.Linear(8, 4), nn.ReLU())  \n",
    "def block2():  \n",
    "    net = nn.Sequential()  \n",
    "    for i in range(4): # 在这里嵌套\n",
    "        net.add_module(f'block {i}', block1())  \n",
    "    return net  \n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))  \n",
    "rgnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a9c59-9f2a-415c-9300-523a9e68e082",
   "metadata": {},
   "source": [
    "分析：在rgnet这个模型中，有两层（块），在第一块（block2）中由Sequential包含了4个子块（block1）\n",
    "因为层是分层嵌套的,所以我们也可以像通过嵌套列表索引一样访问它们。下面,我们访问第一个主要的块中、第二个子块的第一层的偏置项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b163843e-5034-41d2-bdc1-fc0823c1c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1454, -0.0033,  0.2428,  0.2983,  0.3111,  0.4952,  0.4737, -0.3738])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49dcf1-9881-432c-905b-b3d64a6e031e",
   "metadata": {},
   "source": [
    "## 二、参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ae437-109f-4950-9479-f673b8a4df65",
   "metadata": {},
   "source": [
    "### 1.内置初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e70e3-3d2f-44a7-9b72-5515b5d23238",
   "metadata": {},
   "source": [
    "（1）将所有权重参数初始化为标准差为0.01的高斯随机变量,且将  偏置参数设置为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c8d3355e-0eb6-4c2e-8bc4-75e6d4c40612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0057, -0.0241, -0.0078,  0.0126]), tensor(0.))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):  \n",
    "    if type(m) == nn.Linear:  \n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)  \n",
    "        nn.init.zeros_(m.bias)  \n",
    "net.apply(init_normal)  \n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2c6fc-a1d6-471c-b1f6-1c513f7a542a",
   "metadata": {},
   "source": [
    "（2）将所有参数初始化为给定的常数,比如初始化为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d352aa13-a151-43ae-a20d-abb4a497dc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):  \n",
    "    if type(m) == nn.Linear:  \n",
    "        nn.init.constant_(m.weight, 1)  \n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)  \n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae4d61-7a35-48d3-a36b-9e33a335ec92",
   "metadata": {},
   "source": [
    "（3）对某些块应用不同的初始化方法。    \n",
    "例如,下面我们使用Xavier初始化方法初始化第一个神经网络  层,然后将第三个神经网络层初始化为常量值42。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8bdce85b-9c6a-4361-9d0b-d0343655fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3067,  0.7016, -0.3640,  0.6962])\n",
      "tensor([42., 42., 42., 42., 42., 42., 42., 42.])\n"
     ]
    }
   ],
   "source": [
    "def init_xavier(m):  \n",
    "    if type(m) == nn.Linear:  \n",
    "        nn.init.xavier_uniform_(m.weight)  \n",
    "def init_42(m):  \n",
    "    if type(m) == nn.Linear:  \n",
    "        nn.init.constant_(m.weight, 42)  \n",
    "net[0].apply(init_xavier)  \n",
    "net[2].apply(init_42)  \n",
    "print(net[0].weight.data[0])  \n",
    "print(net[2].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ce6de-75a5-4968-92f8-c45a2e4c1709",
   "metadata": {},
   "source": [
    "## 三、参数绑定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "20a14202-bbc6-4eee-a38f-5f2cfe70f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称,以便可以引用它的参数  \n",
    "shared = nn.Linear(8, 8)  \n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),  shared, nn.ReLU(),  shared, nn.ReLU(),  nn.Linear(8, 1))  \n",
    "net(X)  # 检查参数是否相同  \n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])  \n",
    "net[2].weight.data[0, 0] = 100  # 确保它们实际上是同一个对象,而不只是有相同的值  \n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1aa1ba-5bb4-4ede-a50e-6d280c870d76",
   "metadata": {},
   "source": [
    "如果我们改变其中一个参数,另一个参数也会改变。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
